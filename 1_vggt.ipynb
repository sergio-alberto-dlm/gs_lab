{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"submodules\", \"vggt\")))\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Append the path to 'submodules/vggt'\n",
    "sys.path.append(os.path.join(notebook_dir, \"submodules\", \"vggt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from submodules.vggt.vggt.models.vggt import VGGT\n",
    "from submodules.vggt.vggt.utils.load_fn import load_and_preprocess_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---> load model \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16\n",
    "\n",
    "# Initialize model\n",
    "model = VGGT()\n",
    "# Load the state dict\n",
    "checkpoint = torch.load(\"submodules/vggt/checkpoints/model.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submodules.vggt.vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from submodules.vggt.vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "\n",
    "images_names = os.listdir(\"data/leonora/ship_of_cranes/7_views\")\n",
    "images_paths = [os.path.join(\"data/leonora/ship_of_cranes/7_views\", name) for name in images_names]\n",
    "images = load_and_preprocess_images(images_paths).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # with torch.cuda.amp.autocast(dtype=dtype):\n",
    "    images = images[None]  # add batch dimension\n",
    "    aggregated_tokens_list, ps_idx = model.aggregator(images)\n",
    "                \n",
    "    # Predict Cameras\n",
    "    pose_enc = model.camera_head(aggregated_tokens_list)[-1]\n",
    "    # Extrinsic and intrinsic matrices, following OpenCV convention (camera from world)\n",
    "    extrinsic, intrinsic = pose_encoding_to_extri_intri(pose_enc, images.shape[-2:])\n",
    "\n",
    "    # Predict Depth Maps\n",
    "    depth_map, depth_conf = model.depth_head(aggregated_tokens_list, images, ps_idx)\n",
    "\n",
    "    # Predict Point Maps\n",
    "    point_map, point_conf = model.point_head(aggregated_tokens_list, images, ps_idx)\n",
    "        \n",
    "    # Construct 3D Points from Depth Maps and Cameras\n",
    "    # which usually leads to more accurate 3D points than point map branch\n",
    "    point_map_by_unprojection = unproject_depth_map_to_point_map(depth_map.squeeze(0), \n",
    "                                                                extrinsic.squeeze(0), \n",
    "                                                                intrinsic.squeeze(0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392, 518, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_map[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 392, 518])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "img = Image.open(\"data/leonora/ship_of_cranes/7_views/IMG_1.jpg\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((392, 518)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "img_resized = transform(img)\n",
    "img_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────── <span style=\"font-weight: bold\">viser</span> ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8085   │\n",
       "│   Websocket │ ws://0.0.0.0:8085     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────── \u001b[1mviser\u001b[0m ───────────────╮\n",
       "│             ╷                       │\n",
       "│   HTTP      │ http://0.0.0.0:8085   │\n",
       "│   Websocket │ ws://0.0.0.0:8085     │\n",
       "│             ╵                       │\n",
       "╰─────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_625990/1840399523.py:17: DeprecationWarning: ViserServer.add_point_cloud has been deprecated, use ViserServer.scene.add_point_cloud instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_point_cloud(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server running. Open your browser and go to http://<your-server-ip>:8080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import viser\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "idx_img = 0\n",
    "server = viser.ViserServer()\n",
    "points = point_map[0][idx_img].view(-1, 3).cpu().numpy()\n",
    "\n",
    "img = Image.open(\"data/leonora/ship_of_cranes/7_views/IMG_1.jpg\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((392, 518)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "colors = transform(img).view(-1, 3).numpy()\n",
    "\n",
    "# Add point cloud to the scene\n",
    "server.add_point_cloud(\n",
    "    name=\"my_pointcloud\",\n",
    "    points=points,\n",
    "    colors=colors,\n",
    ")\n",
    "\n",
    "print(\"Server running. Open your browser and go to http://<your-server-ip>:8080\")\n",
    "\n",
    "# Keep the server alive (usually at the end)\n",
    "import time\n",
    "while True:\n",
    "    time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
